---
title: ''
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = NA)
```


[//]: <> (Primera pagina.) 

[![image](/home/ion/TFM/logo_iebs.png)]()

\vspace{62pt}


\begin{center} 

  
CLASIFICACIÓN FRECUENCIAL DE MUESTRAS DE SONIDO A TRAVES DE LA REDUCCIÓN DE DIMENSIONALIDAD MEDIANTE ESCALAMIENTO MULTIDIMENSIONAL


\end{center}


\vspace{68pt}

ALUMNO:

\vspace{6pt}

Alberto Jiménez Rodríguez

\vspace{80pt}

PROGRAMA: 

MASTER EN  BUSSINESS INTELLIGENCE AND DATA SCIENCE

\vspace{96pt}

NOMBRE DEL PROYECTO:	

MACHINE LEARNING APLICADO AL DISEÑO DE SONIDO

























\newpage



# CONTENIDO 

\vspace{60pt}



[RESUMEN...............................................................3](#resumen)
\vspace{12pt}

[INTRODUCCIÓN........................................................4](#introducción)
\vspace{12pt}

[ESTADO DEL ARTE.....................................................5](#estado-del-arte)
\vspace{12pt}

[OBJETIVOS.............................................................6](#objetivos)
\vspace{12pt}

[SOLUCIÓN PLANTEADA...............................................7](#solución-planteada)
\vspace{12pt}

[Código fuente............................................................9](#codigo)
    
\vspace{12pt}


1 [Muestras y análisis.....................................................11](#muestras-y-análisis)

  + 1.1 [Espectrogramas................................................12](#espectrogramas)

  + 1.2 [Parametros.....................................................14](#parametros-acusticos-de-las-muestras)



2 [Definir un modelo......................................................15](#definir-el-modelo)

  + 2.1 [Matriz de similitud.............................................16](#crear-la-matriz-de-similitud)

  + 2.2 [Calculo de distancias...........................................16](#calculo-de-las-distancias)

  + 2.3 [Escalado multidimensional......................................16](#escalado-multidimensional)



3  [Evaluar modelo...17](#evaluar-el-modelo)

  + 3.1 [Visualizacion en un sistema de coordenadas.....................17](#visualizacion)

\vspace{12pt}


[CONCLUSIONES Y TRABAJOS FUTUROS............................19](#conclusiones-y-trabajos-futuros)
\vspace{12pt}


[RESULTADOS...........................................................21](#resultados)
\vspace{12pt}


[REFERENCIAS.........................................................23](#referencias)























\newpage
## RESUMEN

\vspace{20pt}

Ejercicio de aproximación a una de las técnicas de Machine Learning, mediante un conjunto de muestras de audio. El objetivo es aplicar un método de organización muy utilizado en la rama del aprendizaje no supervisado y relacionado con la reducción de dimensionalidad, este método de clasificación se realiza a través del escalamiento multidimensional.   


El escalamiento multidimensional (MDS) permite visualizar el nivel de similitud de los elementos individuales de un conjunto, es una de las formas de reducción de dimensión no lineal. Esta técnica de escalamiento multidimensional se llevará a cabo mediante el análisis frecuencial previo de cada uno de los elementos del conjunto obteniendo la diferencia o similitud entre las muestras de nuestro conjunto a nivel frecuencial. 


El algoritmo MDS tiene como objetivo colocar cada objeto en un espacio N-dimensional para que las distancias entre los objetos se mantengan de la mejor manera posible, mas tarde, a cada objeto se le asignan coordenadas en cada una de las N dimensiones permitiendo visualizar el resultado.


 




\vspace{40pt}

## Abstract

\vspace{20pt}

Exercise of approach to one of the techniques of Machine Learning, through a set of audio samples. The aim is to apply a method of organization widely used in the branch of unsupervised learning and related to the reduction of dimensionality, this method of classification is done through multidimensional scaling.   


The multidimensional scaling (MDS) allows visualizing the level of similarity of individual elements of a set, is one of the forms of non-linear dimensional reduction. This technique of multidimensional scaling will be carried out through the previous frequency analysis of each of the elements of the set obtaining the difference or similarity between the samples of our set at frequency level. 


The MDS algorithm aims to place each object in N-dimensional space so that the distances between the objects are maintained in the best possible way. Later, each object is assigned coordinates in each of the N dimensions allowing to graph the result.


\vspace{6pt}




























\newpage
## INTRODUCCIÓN

\vspace{30pt}

En el ámbito audiovisual existe un perfil profesional que es el diseñador de sonido. Este es un profesional por lo general independiente que se dedica a la creación de efectos sonoros con el objetivo de narrar, personificar, generar emociones, retratar espacios sonoros, épocas, y en definitiva crear un universo sonoro con una identidad particular dentro del contexto audiovisual en el que esté trabajando. 

\vspace{6pt}

El resultado de esta labor es un trabajo metódico y artesanal donde el volumen de archivos de sonido que se genera para el desarrollo de un proyecto suele ser enorme, por lo que esto puede ocasionar una perdida de perspectiva tímbrica en el proceso creativo, pues a mayor volumen de muestras, es fácil que los sonidos acaben siendo parecidos y como consecuencia de ello la originalidad del trabajo verse mermada.

\vspace{6pt}

Una herramienta que analice las muestras (únicamente desde la perspectiva frecuencial) en las que el profesional está trabajando y determine si existe o no similitud entre las mismas es una solución que ahorraría tiempo a la hora de tomar decisiones de carácter creativo, pues permitirá establecer cuál es la predominancia frecuencial del conjunto y por tanto conocer cuál es el carácter tímbrico de ese grupo de muestras.

\vspace{6pt}

La solución propuesta para conseguir tal fin es la aplicación de una de las técnicas vistas en el módulo de Análisis predictivo con Machine Learning (Diego Calvo), referente al escalamiento multidimensional.

Si bien es cierto que la solución no es innovadora, tampoco pretende serlo. Únicamente se busca la implementación del conocimiento adquirido en ML de la manera mas original posible evitando la dependencia de datasets externos a través de un campo como es el audio en el que me siento cómodo y siendo lo más honesto con lo aprendido en el curso.






















\newpage
## ESTADO DEL ARTE

\vspace{30pt}

Fuentes que he utilizado como punto de partida y en las que inspirado el trabajo:


\vspace{15pt}

Clase práctica de Machine Learning del Master de IEBS (Bussiness Intelligence y Big Data) con Diego Calvo sobre la reducción de dimensionalidad y el escalamiento multidimensional.

\vspace{15pt}

Caso de estudio en la investigación de los murciélagos con alas de disco de Spix (Thyroptera tricolor), biblioteca de funciones llamada warbleR.

https://marce10.github.io/2020/06/15/Automatic_signal_detection-_a_case_study.html


\vspace{15pt}

Sononym. "navegador de muestras de audio", utilidad que permite la catalogación de las muestras de audio a traves del analisis de las muestras.

No he podido encontrar los principios científicos en los que se apoya esta aplicación de software, porque forma parte del conocimiento interno de una empresa privada y por ese motivo no son públicos, sin embargo el producto hace referencia al análisis de las muestras mediante Machine Learning para hacer la categorización de las muestras.

https://www.sononym.net/docs/manual/similarity-search/#similarity-ratings


\vspace{45pt}



















\newpage

## OBJETIVOS

\vspace{30pt}

Visualizar la relación existente que hay entre los elementos de un conjunto de muestras de sonido y sus frecuencias.

\vspace{12pt}

La estrategia para conseguirlo será a traves de los siguientes puntos:

\vspace{12pt}

1. Tomar unas muestras como referencia y analizar el contenido frecuencial de las mismas.


2. Definir un modelo:

    + 2.1 Crear la matriz de similitud.
    
    + 2.2 Calcular las distancias entre los elementos.
    
    + 2.3 Ejecutar un escalado multidimensional.

3. Evaluar el modelo:

    + 3.1 Visualizacion en un sistema de coordenadas.
















\newpage
## SOLUCIÓN PLANTEADA

\vspace{15pt}


La metodología utilizada se basará en la comparación de un conjunto de muestras de audio a modo de referencia que permitirán comprobar el funcionamiento correcto del modelo.


\vspace{60pt}

[![image](/home/ion/TFM/TFM_iebs/TFM_iebs/Script/Diagrama1.jpeg)]()



\newpage


Se han creado 6 muestras de audio partiendo del mismo origen y con las siguientes caracteristicas:


|X_pitch-11.wav*            | Wave Object   |  
|---------------------------|---------------| 
|Number of Samples:         |   13020       |  
|Duration (seconds):        |   0.295       | 
|Samplingrate (Hertz):      |   44100       |  
|Channels (Mono/Stereo):    |   Mono        | 
|PCM (integer format):      |   TRUE        |
|Bit (8/16/24/32/64):       |   16          |
|Peak Freq                  | 96Hz@ -13,6dB | 
|                           |               |

|X_pitch-11_d.wav           | Wave Object     |  
|---------------------------|-----------------| 
|Peak Freq                  | 90Hz@ -7,4dB    |

|X_pitch-11_dd.wav          | Wave Object     |  
|---------------------------|-----------------|  
|Peak Freq                  | 80Hz@ -4,4dB    |


|X_pitch-22_d.wav           | Wave Object     |  
|---------------------------|-----------------|  
|Peak Freq                  | 182Hz@ -15,13dB |


|X_pitch-11_dd.wav          | Wave Object     |  
|---------------------------|-----------------|  
|Peak Freq                  | 169Hz@ -8,7dB   |


|X_pitch-11_dd.wav          | Wave Object     |  
|---------------------------|-----------------|  
|Peak Freq                  | 147Hz@ -5,2dB   |


La duracion de las muestras es la misma, el motivo es evitar que las longitudes de muestras diferentes alteren los resultados del analisis frecuencial, subrayar que el motivo por el cual las muestras son tan graves es porque en un rango de frecuencia tan bajo permite añadir frecuencias mas altas mediante el efecto de distorsión.

Los elementos que conforman nuestro conjunto de test son dos grupos de muestras que parten de un origen comun "**X_pitch-11.wav**":

El primer grupo de muestras hace referencia a aquellas que tienen la nomenglatura **X_pitch-11_xx**, muestras unicamente modificadas a nivel armónico mediante un efecto de distorisión aplicado en **X_pitch-11_d** una vez y una vez más en **X_pitch-11_dd** con los mismos parametros de distorsión. 

El segundo grupo de muestras es **X_pitch-22_xx**, muestras a las que previamente se les ha doblado la frecuencia con respecto a X_pitch-11 para posteriormente distorsionar las muestras con los mismos parámetros de distorsión aplicados en el primer grupo.

Con este conjunto se pretende visualizar el funcionamiento de nuestro modelo poniendo especial enfasis en la relación frecuencial entre las muestras y la distorsión aplicada a cada una de ellas.





\vspace{15pt}


\newpage

## Codigo

``` {r 01 Instalación de librerias, echo=TRUE, eval=TRUE, warning=FALSE, message = FALSE}
library(imager) 
library()
library(tuneR)
library(knitr)
library(NatureSounds)
library(seewave)
library(warbleR) 
library(igraph) 
```


```{r 02 Carga de las muestras en el espacio de trabajo, eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
todas_las_muestras <- selection_table(whole.recs = TRUE, extended = TRUE)
```


```{r 03 Parametros acusticos, echo=TRUE, eval=TRUE, warning=FALSE}
sample_acoust_param <- na.omit(specan(todas_las_muestras, wl = 512, fsmooth = 0.1, 
                                      threshold = 10, wn = "hanning",
                                      flim = c(0, 22), bp = c(0,20), 
                                      fast.spec = FALSE, ovlp = 50, 
                                      pal = reverse.gray.colors.2,
                                      widths = c(2, 1), main = NULL, 
                                      plot = TRUE, all.detec = FALSE)) 
```


```{r 04 Xcorr , eval=TRUE, echo=TRUE, warning=FALSE}
xcor <- xcorr(todas_las_muestras, bp = c(0, 20), wl = 512, ovlp = 99, path = NULL,
              type = "mfcc", method= 1, na.rm = TRUE)
```


```{r 05 Matriz de similaridad , echo=TRUE, eval=TRUE,warning=FALSE}
distancia <- dist(xcor, method = "euclidean")
```


```{r 06 PCA, echo=TRUE, eval=TRUE,warning=FALSE}
valores <- cmdscale(distancia, eig = T)
```


```{r 07 PLOT-1 , echo=TRUE, eval=FALSE,warning=FALSE}
old.par <- par(mfrow=c(1, 2))

#plot(modelo, type = "p", xlab = "Coord 1", ylab = "Coord 2")
plot(xcor, type = "p", xlab = "Coord 1", ylab = "Coord 2")
text(xcor[,1],xcor[,2], labels = rownames(xcor), pos = 2, cex = 0.8 )
matplot(xcor, lty = 1)

par(old.par)
```


```{r 08 PLOT-2, echo=TRUE, eval=FALSE,warning=FALSE}
plot(sample_acoust_param$dfrange)
title(main = "frecuencia dominante", cex = 1.5,col = "red", font = 3)
```

```{r 09 PLOT-3, echo=TRUE, eval=FALSE,warning=FALSE}
old.par <- par(mfrow=c(2, 3))

plot(sample_acoust_param$meanfreq)
title(main = "Frecuencia media", cex = 1.5,col = "red", font = 3)

plot(sample_acoust_param$sd)
title(main = "desviación estandar", cex = 1.5,col = "red", font = 3)

plot(sample_acoust_param$skew)
title(main = "asimetria", cex = 1.5,col = "red", font = 3)

plot(sample_acoust_param$kurt)
title(main = "Pico del espectro", cex = 1.5,col = "red", font = 3)

plot(sample_acoust_param$sp.ent) 
title(main = "entropía espectral", cex = 1.5,col = "red", font = 3)

plot(sample_acoust_param$dfrange)
title(main = "frecuencia dominante", cex = 1.5,col = "red", font = 3)

par(old.par)
```



```{r, echo=FALSE, eval=FALSE,warning=FALSE}
valores$eig
```


```{r, echo=FALSE, eval=FALSE,warning=FALSE}
valores$GOF
```

```{r,  echo=TRUE, eval=FALSE,warning=FALSE}

graf <- graph.tree(ncol(xcor),mode = c("in"))
V(graf)$label <- colnames(xcor)

layout <- layout.mds(graf, dist = as.matrix(distancia))

plot(graf, vertex.size = .1)
```







































\newpage

## 1 Muestras y análisis

Visualizamos las muestras cargadas en el espacio de trabajo



```{r 02b Muestras del espacio de trabajo, echo=TRUE, warning=FALSE}
todas_las_muestras 
```


\newpage

## 1.1 Espectrogramas

Representación en tres dimensiones, temporal, frecuencial y amplitud de la distribución de energía de una señal.

El espectrograma es el resultado de calcular la distribución de las amplitudes para cada frecuencia de un fenómeno ondulatorio que sea lal superposición de ondas de varias frecuencias de tramas de una señal. Una gráfica tridimensional que representa la energía del contenido frecuencial de la señal según va variando a lo largo del tiempo.


[![image](/home/ion/TFM/TFM_iebs/TFM_iebs/Script/X_pitch-11.png)]()

\vspace{15pt}

[![image](/home/ion/TFM/TFM_iebs/TFM_iebs/Script/X_pitch-11_d.png)]()

\vspace{15pt}

[![image](/home/ion/TFM/TFM_iebs/TFM_iebs/Script/X_pitch-11_dd.png)]()

\vspace{15pt}

[![image](/home/ion/TFM/TFM_iebs/TFM_iebs/Script/X_pitch-22.png)]()

\vspace{15pt}

[![image](/home/ion/TFM/TFM_iebs/TFM_iebs/Script/X_pitch-22_d.png)]()

\vspace{15pt}

[![image](/home/ion/TFM/TFM_iebs/TFM_iebs/Script/X_pitch-22_dd.png)]()

\newpage

##  1.2 Parametros acusticos de las muestras

```{r 03b Parametros acusticos, echo=TRUE, eval=TRUE, warning=FALSE}
head(sample_acoust_param,1)
```

**duration**: longitud de la señal en segundos.

\vspace{6pt}

**meanfreq**: frecuencia media (en kHz). Media del espectro de frecuencias (es decir, media ponderada de la frecuencia por la amplitud dentro del paso de banda suministrado). 

\vspace{6pt}

**sd**: Desviación estándar de la frecuencia (en kHz).

\vspace{6pt}

**freq.median**: frecuencia media. La frecuencia en la que la señal se divide en dos intervalos de frecuencia de igual energía (en kHz).

\vspace{6pt}

**freq.Q25**: la primera frecuencia de cuartil. La frecuencia en la que la señal se divide en dos intervalos de frecuencia de 25% y 75% de energía respectivamente (en kHz).

\vspace{6pt}

**freq.Q75**: frecuencia del tercer cuartil. La frecuencia en la que la señal se divide en dos intervalos de frecuencia de 75% y 25% de energía respectivamente (en kHz). 

\vspace{6pt}

**freq.IQR**: rango de frecuencia intercuartil. Gama de frecuencias entre 'freq.Q25' y 'freq.Q75' (en kHz).

\vspace{6pt}

**time.median**: tiempo medio. El tiempo en el que la señal se divide entre dos intervalos.

\vspace{6pt}

**time.Q25**: el primer tiempo de cuartil. El tiempo en el que la señal se divide en dos intervalos de tiempo de 25% y 75% de energía respectivamente (en s).

\vspace{6pt}

**time.Q75**: el tiempo del tercer cuartil. El tiempo en el que la señal se divide en dos intervalos de tiempo de 75% y 25% de energía respectivamente (en s).

\vspace{6pt}

**time.IQR**: rango de tiempo intercuartílico. Rango de tiempo entre "tiempo.Q25" y "tiempo.Q75" (en s).

\vspace{6pt}

**skew**: asimetría. Asimetría del espectro.

\vspace{6pt}

**kurt**: Picos del espectro

\vspace{6pt}

**sp.ent**: Distribución energética del espectro de frecuencias. Tono puro ~ 0; ruidoso ~ 1.

\vspace{6pt}

**time.ent**: entropía del tiempo. Distribución de la energía en la envoltura del tiempo. Tono puro ~ 0; ruidoso ~ 1.

\vspace{6pt}

**entropy**:  entropía espectrográfica. Producto del tiempo y la entropía espectral **sp.ent * time.ent**.       

\vspace{6pt}

**sfm**: planitud espectral. Similar a sp.ent (Tono puro ~ 0; ruidoso ~ 1).

\vspace{6pt}

**meandom**: promedio de la frecuencia dominante medida a través de la señal acústica.  

\vspace{6pt}

**mindom**: mínimo de la frecuencia dominante medida a través de la señal acústica.

\vspace{6pt}

**maxdom**: máximo de la frecuencia dominante medida a través de la señal acústica.

\vspace{6pt}

**dfrange**: rango de frecuencia dominante medido a través de la señal acústica.

\vspace{6pt}

**modindx**: índice de modulación. Calculado como la diferencia absoluta acumulada entre las mediciones adyacentes de las frecuencias dominantes dividida por la gama de frecuencias dominantes. 1 significa que la señal no está modulada , 0 que sí lo está.

\vspace{6pt}

**startdom**: medición de la frecuencia dominante al inicio de la señal.

\vspace{6pt}

**enddom**: medición de la frecuencia dominante al final de la señal.

\vspace{6pt}

**dfslope**: pendiente del cambio de la frecuencia dominante a través del tiempo ((enddom-startdom)/duración). Las unidades son kHz/s.

\vspace{6pt}

**meanpeakf**: frecuencia media de pico. Frecuencia con la mayor energía del espectro de frecuencia media.

\vspace{6pt}

## 2 Definir el modelo:

En el procesamiento de señales, la correlación cruzada (o a veces denominada "covarianza cruzada") es una medida de la similitud entre dos señales, frecuentemente usada para encontrar características relevantes en una señal desconocida por medio de la comparación con otra que sí se conoce. Es una función del tiempo relativa a las señales, a veces también se la llama producto escalar desplazado, y tiene aplicaciones en el reconocimiento de patrones y en criptoanálisis de las muestras sonoras por medio de la correlación cruzada tiempo-frecuencia.

Primero se crean las matrices (manteniéndolas internamente como una lista) y se calcula la correlación cruzada en un segundo paso.

El cepstrum de frecuencia de mel (MFC) es una representación del espectro de potencia a corto plazo de un sonido, basado en una transformación coseno lineal de un espectro de potencia logarítmica en una escala de frecuencia de mel no lineal.
\newpage

## 2.1 Matriz de similitud

```{r 04b Xcorr , eval=TRUE, echo=TRUE, warning=FALSE}
xcor 
```
## 2.3 Calculo de las distancias

Medida de distancia especificada para calcular las distancias entre las filas de una matriz de datos.

```{r 05b Matriz de similaridad , echo=TRUE, eval=TRUE, warning=FALSE}
distancia
```

## 2.3 Escalado multidimensional

Escalamiento multidimensional (MDS) de una matriz de datos. También conocido como análisis de coordenadas principales.
```{r 06b PCA, echo=TRUE, eval=TRUE,warning=FALSE}
 
valores_distancia <- as.data.frame(valores$points)
```

\newpage

## 3 Evaluar el modelo

## 3.1 Visualizacion
 

En esta primera representación vemos la disposición de los elementos de nuestro conjunto en un espacio bidimensional indicando cual es la similitud frecuencial que existe entre las muestras. 


Representación de los valores de la matriz de correlación

```{r 3.1 Visualizacion en un sistema de coordenadas , echo=FALSE, eval=TRUE,warning=FALSE}
plot(valores_distancia, type = "p", xlab = "Coord 1", ylab = "Coord 2")
text(valores_distancia[,1],valores_distancia[,2], labels = colnames(valores_distancia), pos = 4, cex = 0.8, offset = 0.2)

```



Únicos elementos (V1 y V2) que reprentan al conjunto de muestras tras haber sido analizado.

\newpage

## CONCLUSIONES 


El objetivo inicial de visualizar las diferencias frecuencial entre los elementos de un conjunto mediante el escalamiento multidimensional ha sido llevado a buen término.

El analisis de la relación frecuencial a partir del conjunto de muestras nos ha dotado de un dataset de datos unico. 

Se ha observado que dado que el ejercicio es muy sencillo y no incluye elementos que tengan en cuenta la duración de las muestras, es necesario que las muestras tengan la misma duración ya que es muy importante a la hora de hacer la correlación frecuencial cruzada y no interferir en el resultado.


\vspace{45pt}

```{r 09b PLOT-3, echo=FALSE, eval=TRUE,warning=FALSE}
old.par <- par(mfrow=c(1, 3))


plot(sample_acoust_param$dfrange)
title(main = "frecuencia dominante", cex = 1.5,col = "red", font = 3)

plot(sample_acoust_param$meanfreq)
title(main = "Frecuencia media", cex = 1.5,col = "red", font = 3)

plot(sample_acoust_param$sd)
title(main = "desviación estandar", cex = 1.5,col = "red", font = 3)

par(old.par)
```

```{r 3.1 Visualizacion en un sistema de coordenadas xcorr, echo=FALSE, eval=TRUE,warning=FALSE}
plot(xcor, type = "p", xlab = "Coord 1", ylab = "Coord 2")
text(xcor[,1],xcor[,2], labels = colnames(xcor), pos = 3.2, cex = 0.6, offset = -0.4)
```
Esta es la representación gráfica de los elementos de la matríz de correlación  


Las muestras a las que no se les a doblado la frequencia **X_pitch-11.wav, X_pitch-11_d.wav, X_pitch-11_dd.wav** en la parte inferior izquierda y aquellas a las que si se les ha modificado la frecuencia **X_pitch-22.wav X_pitch-22_d.wav X_pitch-22_dd.wav** y se encuentran mas a la derecha del gráfico. 

Cabe destacar que ambos grupos de muestras comparten el mismo indice de distorsión en las muestras y que debido a ello se puede verse claramente reflejado en el eje de coordenadas 2. 



```{r 07b PLOT-2 , echo=FALSE, eval=TRUE,warning=FALSE}
matplot(xcor, type = "o",lty = 1:8, lwd = 1 )
```

Cada una de las columnas de la matríz de correlación es comparada contra las demás columnas de la matriz, cada columna representa una muestra de sonido.

Se aprecia que la distorsión máxima que se le ha aplicado a las muestras influyen en el resultado a nivel frecuencial, esto se puede observar en la 2 columna y en la 5, ya que es donde mayor diferencia (son las más distorsionadas) entre las muestras del mismo grupo.

Conforme más arriba en la columna esté la muestra que comparamos más parecido tendrá ese sonido con la muestra comparada.

Se observa que existe una mayor similitud entre la muestra 1 X_pitch-11_d.wav (columna) y las muestras X_pitch-11_dd.wav (2) y X_pitch-11.wav (3) que entre X_pitch-11_d.wav (1) y las muestras X_pitch-22_d.wav (4), X_pitch-22_dd.wav (5) y X_pitch-22.wav (6).


```{r 08b PLOT-2 colorines, echo=FALSE, eval=TRUE,warning=FALSE}
plot(valores_distancia, type = "p", xlab = "Coord 1", ylab = "Coord 2")
text(valores_distancia[,1],valores_distancia[,2], labels = colnames(xcor), pos = 3.2, cex = 0.5, offset = -0.4)
```

Observamos dos grupos claramente diferenciados gracias al análisis de las coordenadas principales (PCA).


\newpage
## RESULTADOS

Para evaluar el modelo le pasaré una libreria de sonido de 8 bits que hice hace un tiempo y que contiene 172 elementos. 

```{r sound_design 01, eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
library(ggplot2)
library(ggfortify)

alles_dir <- "/media/ion/WD-500/back-up/05_Vídeos/Vídeos/04_Portfolio/01_Gameprefabs/8 bit construction kit/Alles"

wav_names <- list.files(alles_dir, pattern = "\\.wav$")

sound_design <- selection_table(whole.recs = TRUE, path = alles_dir, extended = TRUE)

xcor <- xcorr(sound_design, bp = c(0, 20), wl = 512, ovlp = 99, path = alles_dir,
              type = "mfcc", method= 1, na.rm = TRUE,
              parallel = 4)

distancia <- dist(xcor, method = "euclidean")
  
valores <- cmdscale(distancia, eig = T)



autoplot(cmdscale(distancia, eig = T), label = TRUE, label.size = 3, frame = TRUE)

```


Vemos que hay muestras que estan mas "juntas", estas son aquellas que tienen una mayor similitud frecuencial entre ellas. Llegados a este punto dariamos por concluida la busqueda de una herramienta que nos permitiera saber cual es la predominancia frecuencial de nuestra libreria de sonidos.














\vspace{15pt}





\newpage
## REFERENCIAS

\vspace{15pt}



Araya-Salas, M. and Smith-Vidaurre, G. (2017), warbleR: an r package to streamline analysis of animal acoustic signals. Methods Ecol Evol. 8, 184-191.

Maechler, M., Rousseeuw, P., Struyf, A., Hubert, M., Hornik, K.(2019).  cluster: Cluster Analysis Basics and Extensions. R package
  version 2.1.0
  
NOTE: please also cite the 'tuneR' and 'seewave' packages if you use any spectrogram-creating or acoustic-measuring function
  

Uwe Ligges, Sebastian Krey, Olaf Mersmann, and Sarah Schnackenberg (2018). tuneR: Analysis of Music and Speech. URL: https://CRAN.R-project.org/package=tuneR


Yihui Xie (2020). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.30.

  Yihui Xie (2015) Dynamic Documents with R and knitr. 2nd edition. Chapman and Hall/CRC. ISBN 978-1498716963

  Yihui Xie (2014) knitr: A Comprehensive Tool for Reproducible Research in R. In Victoria Stodden, Friedrich Leisch and Roger D. Peng,
  editors, Implementing Reproducible Computational Research. Chapman and Hall/CRC. ISBN 978-1466561595
  

Araya-Salas, M. (2018), *NatureSounds: a collection of animal sound for bioacoustic analysis in the R environment*. R package version
  1.1.0.

Sueur J, Aubin T, Simonis C (2008). seewave: a free modular tool for sound analysis and synthesis. Bioacoustics, 18: 213-226

Araya-Salas, M. and Smith-Vidaurre, G. (2017), warbleR: an r package to streamline analysis of animal acoustic signals. Methods Ecol
  Evol. 8, 184-191.

  

